{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f114a9eb-bef0-48ca-baf6-b4a03b972a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "from numpyro.contrib.funsor import config_enumerate\n",
    "from jax.random import PRNGKey\n",
    "\n",
    "import arviz as az\n",
    "\n",
    "from typing import Optional\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ee8fd-2828-4b64-84dc-ef31b6538238",
   "metadata": {},
   "source": [
    "Input data is fairly straightforward. We have two numpy rows: one, a series of event detections, and one, a series of looks. Each time we look at a location we can either have a detection or non-detection.\n",
    "\n",
    "We model each location where there is a leak as having a probability $P$ of being detected. We draw these probabilities from a beta distribution $P_i$ ~ Beta(1, $\\beta$ )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e78a23f4-93bf-494a-a527-d8dad5063844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "500b1333-0c1f-4178-bfc9-21cb2f6436ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_detections = np.concatenate((np.random.randint(0,10, 30), np.zeros(20)))\n",
    "n_looks = n_detections + np.random.randint(1,50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2928499-792c-42cc-bc50-36cfcd5388e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11904762, 0.13333333, 0.10909091, 0.25714286, 0.4375    ,\n",
       "       0.        , 0.125     , 0.03225806, 0.27272727, 0.        ,\n",
       "       0.18518519, 0.13888889, 0.125     , 0.08695652, 0.        ,\n",
       "       0.17142857, 0.03571429, 0.31578947, 0.38461538, 0.33333333,\n",
       "       0.02702703, 0.14893617, 0.03921569, 0.14285714, 0.20512821,\n",
       "       0.11538462, 0.03921569, 0.07894737, 0.22857143, 0.17647059,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_detections/n_looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194600cf-bbb8-4184-9f7f-ec334b6eb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "from numpyro.contrib.funsor import config_enumerate\n",
    "from jax.random import PRNGKey\n",
    "\n",
    "import arviz as az\n",
    "\n",
    "from typing import Optional\n",
    "import numpy.typing as npt\n",
    "\n",
    "# model parameters\n",
    "# determined through diagnostic model fitting\n",
    "# p_leak hyperparameters\n",
    "# generates higher likelihood at low end\n",
    "ALPHA_P_LEAK = 1.0\n",
    "BETA_P_LEAK = 10.0\n",
    "# p_detect hyperparameters\n",
    "# expectation at 0.45, sorta u shaped weighted low\n",
    "ALPHA_D = 1.0\n",
    "LAMBDA_BETA_D = 1.0\n",
    "BETA_D_OFFSET = 0.5\n",
    "\n",
    "def unpack_data(data):\n",
    "    n_passes = data[\"passes\"].values\n",
    "    n_detects = data[\"detects\"].values\n",
    "\n",
    "    return n_passes, n_detects\n",
    "\n",
    "@config_enumerate\n",
    "def model(\n",
    "    n_passes: npt.NDArray[np.int32],\n",
    "    n_detects: Optional[npt.NDArray[np.int32]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Regional Methane Score Model\n",
    "\n",
    "    This is a numpyro model that estimates a regional `p_leak` based on the number of passes on road segments\n",
    "    and the number of detects/non-detects for those road segments.\n",
    "\n",
    "    This model should be fit with the `fit()` function.\n",
    "    \"\"\"\n",
    "    # global variables\n",
    "    p_leak = numpyro.sample(\"p_leak\", dist.Beta(ALPHA_P_LEAK, BETA_P_LEAK))\n",
    "    leak_mix = dist.Categorical(probs=jnp.array([1 - p_leak, p_leak]))\n",
    "    alpha_d = ALPHA_D\n",
    "    beta_d_ = numpyro.sample(\"beta_d_\", dist.Exponential(LAMBDA_BETA_D))\n",
    "    # offset to prevent large mode at 1\n",
    "    beta_d = numpyro.deterministic(\"beta_d\", beta_d_ + BETA_D_OFFSET)\n",
    "\n",
    "\n",
    "    with numpyro.plate(\"detects\", n_passes.shape[0]):\n",
    "        # latent\n",
    "        p_detect_no = numpyro.sample(\"p_detect\", dist.Beta(alpha_d, beta_d))\n",
    "\n",
    "        # likelihood\n",
    "        numpyro.sample(\n",
    "            \"n_detect_no\",\n",
    "            dist.MixtureGeneral(\n",
    "                leak_mix,\n",
    "                [\n",
    "                    dist.Binomial(n_passes, 0.0),\n",
    "                    dist.Binomial(n_passes, p_detect_no),\n",
    "                ],\n",
    "            ),\n",
    "            obs=n_detects,\n",
    "        )\n",
    "\n",
    "def fit(data, num_warmup=2000, num_samples=4000, num_chains=1):\n",
    "    n_passes, n_detects = unpack_data(data)\n",
    "\n",
    "    if len(n_detects) <= 1:\n",
    "        return None\n",
    "\n",
    "    # setup and run mcmc\n",
    "    nk = NUTS(model)\n",
    "    mcmc = MCMC(nk, num_warmup=num_warmup, num_samples=num_samples, num_chains=num_chains)\n",
    "\n",
    "    rng = PRNGKey(10)\n",
    "    mcmc.run(rng, n_passes, n_detects)\n",
    "\n",
    "    return mcmc\n",
    "\n",
    "\n",
    "def sample_prior(max_passes=10, num_samples=1000):\n",
    "    rng_key = PRNGKey(11)\n",
    "    prior_predictive = Predictive(model, num_samples=num_samples)\n",
    "    prior_predictions = prior_predictive(\n",
    "        rng_key,\n",
    "        n_passes=np.arange(1, max_passes + 1),\n",
    "    )\n",
    "    return prior_predictions\n",
    "\n",
    "def to_arviz(mcmc, data):\n",
    "    # unpack data\n",
    "    n_passes, n_detects = unpack_data(data)\n",
    "\n",
    "    # get prior/posterior/predictive samples\n",
    "    posterior_samples = mcmc.get_samples()\n",
    "    posterior_predictive = Predictive(model, posterior_samples)(\n",
    "        PRNGKey(1), n_passes\n",
    "    )\n",
    "    prior = Predictive(model, num_samples=500)(\n",
    "        PRNGKey(2), n_passes\n",
    "    )\n",
    "\n",
    "    # need to add discrete sampling sites to mcmc\n",
    "    # see note at bottom of: https://num.pyro.ai/en/stable/examples/annotation.html\n",
    "    chain_discrete_samples = jax.tree_util.tree_map(\n",
    "        lambda x: x.reshape((mcmc.num_chains, mcmc.num_samples) + x.shape[1:]),\n",
    "        posterior_predictive)\n",
    "    mcmc.get_samples().update(posterior_predictive)\n",
    "    mcmc.get_samples(group_by_chain=True).update(chain_discrete_samples)\n",
    "\n",
    "    azdat = az.from_numpyro(\n",
    "        mcmc,\n",
    "        prior=prior,\n",
    "        posterior_predictive=posterior_predictive,\n",
    "        coords={\n",
    "            \"segment\": np.arange(len(n_passes)),\n",
    "        },\n",
    "        dims={\n",
    "            \"p_detect\": [\"segment\"],\n",
    "            \"leak\": [\"segment\"],\n",
    "            \"n_detect\": [\"segment\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # expected probability of detect\n",
    "    azdat.posterior[\"E_p_detect\"] = 1 / (1 + azdat.posterior[\"beta_d\"])\n",
    "    azdat.posterior_predictive[\"p_detect\"] = azdat.posterior[\"p_detect\"]\n",
    "    # rename things for use with arviz plotting\n",
    "    azdat.add_groups({\"prior_predictive\": azdat[\"prior\"]})\n",
    "    # add p_detect to observed data\n",
    "\n",
    "    return azdat\n",
    "\n",
    "def score_region(data, num_warmup=2000, num_samples=4000):\n",
    "    mcmc = fit(data, num_warmup, num_samples, 2)\n",
    "\n",
    "    if not mcmc:\n",
    "        return {\n",
    "            \"p_leak\": -1,\n",
    "            \"p_leak_sd\": -1,\n",
    "            \"p_leak_rhat\": -1,\n",
    "            \"beta_d\": -1,\n",
    "            \"beta_d_sd\": -1,\n",
    "            \"beta_d_rhat\": -1\n",
    "        }\n",
    "\n",
    "    azdat = to_arviz(mcmc, data)\n",
    "\n",
    "    # if running multiple models need to free gpu memory, not sure if this works\n",
    "    del mcmc\n",
    "    gc.collect()\n",
    "\n",
    "    return {\n",
    "        \"p_leak\": az.summary(azdat, var_names=[\"p_leak\"]).loc[\"p_leak\", \"mean\"],\n",
    "        \"p_leak_sd\": az.summary(azdat, var_names=[\"p_leak\"]).loc[\"p_leak\", \"sd\"],\n",
    "        \"p_leak_rhat\": az.rhat(azdat, var_names=[\"p_leak\"])[\"p_leak\"].item(),\n",
    "        \"beta_d\": az.summary(azdat, var_names=[\"beta_d\"]).loc[\"beta_d\", \"mean\"],\n",
    "        \"beta_d_sd\": az.summary(azdat, var_names=[\"beta_d\"]).loc[\"beta_d\", \"sd\"],\n",
    "        \"beta_d_rhat\": az.rhat(azdat, var_names=[\"beta_d\"])[\"beta_d\"].item()\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
